{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QIE Implementaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implement a QIE approch named algorithm 2.1 from the paper A. Mandelbaum and S. Zeltyn, “Estimating characteristics of queueingnetworks  using  transactional  data\", Queueing systems,  vol.  29,  no.  1,pp. 75–127, 1998."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_continuity(df , max_enqueue):\n",
    "    df_1 = df[df['service'] <= max_enqueue]\n",
    "    df_1 = df_1.sort_values(by=['service']) \n",
    "    df_1 = df_1.reset_index()\n",
    "    z = []\n",
    "    for i in range(len(df_1)):\n",
    "        z.append(df_1.at[i, 'service'])\n",
    "    if max_enqueue != df_1.at[len(df_1)-1, 'service']:\n",
    "        z.append(max_enqueue)\n",
    "        flag = 1\n",
    "    else:\n",
    "        flag = 0   \n",
    "    minim = z[0]\n",
    "    z = list(map(lambda x: x - minim, z))\n",
    "    return z, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ex_times(df , max_enqueue):\n",
    "    minim = df['service'].min()\n",
    "    df_1 = df[df['service'] > max_enqueue]\n",
    "    df_1 = df_1.sort_values(by=['service']) \n",
    "    df_1 = df_1.reset_index()\n",
    "    z = []\n",
    "    for i in range(len(df_1)):\n",
    "        z.append(df_1.at[i, 'service'])\n",
    "    z = list(map(lambda x: x - minim, z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The buliding based on index that start from 0 to customers\n",
    "# Build a list of tupels (left= index g_i, right= possible admissible_states)\n",
    "def build_admissible_states(m, l):\n",
    "    G = []\n",
    "    G.append((0,[0]))\n",
    "    for i in range(1,m):\n",
    "        num_list = []\n",
    "        for j in range(i,l):\n",
    "            num_list.append(j)\n",
    "        G.append((i,num_list))\n",
    "    return G\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one transtion matrix between two djacent admissible states \n",
    "def build_transition_matrix(current_g, current_zi, former_g, z, arrival_rate, upper_boundary_condition, flag):\n",
    "    p = [] # initiation\n",
    "    if flag == 0: #Regular transition\n",
    "        x = arrival_rate*(z[current_zi]-z[current_zi-1])\n",
    "        value = math.exp(-x)\n",
    "        calac_dic = {\n",
    "            0: value \n",
    "        }\n",
    "        \n",
    "        for i in range(1, (current_g[len(current_g)-1] - former_g[0]) + 1 ):\n",
    "            value = value*(x/i)\n",
    "            calac_dic[i] = value\n",
    "            \n",
    "        for i in range(len(former_g)):\n",
    "            k_i = former_g[i] #row index of the matrix\n",
    "            temp = []\n",
    "            for j in range(len(current_g)):\n",
    "                k_j = current_g[j] # column index of the matrix \n",
    "                if k_i <= k_j: # enqueues are accumulate -> no option to decrease \n",
    "                    px = calac_dic[k_j-k_i]\n",
    "                    temp.append(px)        \n",
    "                else: \n",
    "                    temp.append(0)\n",
    "            p.append(temp)\n",
    "            \n",
    "    else: # transtion matrix between t_m to t_m+1 (flag==1)\n",
    "        x = arrival_rate*(z[current_zi]-z[current_zi-1])\n",
    "        value = math.exp(-x)\n",
    "        temp = []\n",
    "        k_j = current_g[0] # column index of the matrix\n",
    "        k_i = former_g[len(former_g)-1]\n",
    "        p.append([value])\n",
    "        pp = 1 #delete after it work\n",
    "        for i in range(len(former_g)-2,-1,-1): # reverse run to reduce calculations\n",
    "            k_i = former_g[i] #row index of the matrix\n",
    "            value = (value*x)/(pp)\n",
    "            p.append([value])\n",
    "            pp += 1\n",
    "        p.reverse()\n",
    "              \n",
    "    P = np.matrix(p) #convert to Numpy matrix\n",
    "    return P \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place all the transition matrices in one list\n",
    "def build_transition_matrices(G, z, m, upper_boundary_condition, arrival_rate, max_list ):\n",
    "  \n",
    "    #Transtion between admissible states - return P (list) of Numpy matrices\n",
    "    P = []\n",
    "    list_num = 0\n",
    "    j = 0 \n",
    "    for i in range(len(G)-1): \n",
    "        p = build_transition_matrix(G[i+1][1], G[i+1][0],\n",
    "                                    G[i][1], z, arrival_rate, upper_boundary_condition, flag = 0)\n",
    "        P.append(p)\n",
    "        if len(P) == max_list:\n",
    "            with open('P_%d.pkl' %(list_num), 'wb') as outfile:\n",
    "                pickle.dump(P, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "            P = []\n",
    "            list_num +=1\n",
    "             \n",
    "    p = build_transition_matrix([upper_boundary_condition-1],m,\n",
    "                                G[len(G)-1][1], z, arrival_rate, upper_boundary_condition, flag = 1)\n",
    "    P.append(p)\n",
    "    with open('P_%d.pkl' %(list_num), 'wb') as outfile:\n",
    "        pickle.dump(P, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    del P\n",
    "    \n",
    "\n",
    "    return list_num +1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_taboo_probabilities(P_num):\n",
    "    W_start = []\n",
    "    for i in range(P_num):\n",
    "        with open('P_%d.pkl' %(i), 'rb') as infile:\n",
    "            P = pickle.load(infile)\n",
    "        if i == 0:\n",
    "            w_left = P[0]\n",
    "        else:\n",
    "            w_left = np.matmul(w_left, P[0])\n",
    "        W_start.append(w_left)\n",
    "        for j in range(1,len(P)):\n",
    "            w_left = np.matmul(w_left, P[j])\n",
    "            W_start.append(w_left)\n",
    "        with open('TP_1_%d.pkl' %(i), 'wb') as outfile:\n",
    "            pickle.dump(W_start, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "        W_start = []\n",
    "        \n",
    "    W_end = []    \n",
    "    w_right = P[len(P)-1]\n",
    "    W_end.append(w_right)\n",
    "    TP_m_num = P_num\n",
    "    if len(P) > 1:\n",
    "        for j in range(len(P)-2,0,-1):\n",
    "            w_right = np.matmul(P[j], w_right)\n",
    "            W_end.append(w_right)\n",
    "        W_end.reverse()\n",
    "        with open('TP_m_%d.pkl' %(P_num-1), 'wb') as outfile:\n",
    "                pickle.dump(W_end, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "        W_end =[]\n",
    "        w_right = np.matmul(P[0], w_right)\n",
    "        W_end.append(w_right)\n",
    "    else:\n",
    "        TP_m_num = TP_m_num -1\n",
    "        os.remove('TP_1_%d.pkl' %(P_num-1))\n",
    "    os.remove('P_%d.pkl' %(P_num-1))    \n",
    "    for i in range(P_num-2,-1,-1):\n",
    "        with open('P_%d.pkl' %(i), 'rb') as infile:\n",
    "            P = pickle.load(infile)\n",
    "        for j in range(len(P)-1,0,-1):\n",
    "            w_right = np.matmul(P[j], w_right)\n",
    "            W_end.append(w_right)\n",
    "        W_end.reverse()\n",
    "        with open('TP_m_%d.pkl' %(i), 'wb') as outfile:\n",
    "            pickle.dump(W_end, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "        W_end =[]\n",
    "        w_right = np.matmul(P[0], w_right)\n",
    "        W_end.append(w_right)\n",
    "        os.remove('P_%d.pkl' %(i))\n",
    "        \n",
    "        \n",
    "    return TP_m_num\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculating_distribution(TP_m_num, z, m, upper_boundary_condition ):\n",
    "    df = pd.DataFrame(z,columns = ['time'])\n",
    "    df.reset_index(inplace=True)\n",
    "    for i in range(1,upper_boundary_condition+2):\n",
    "        df['cumulative_enqueue_%d'%(i)] = 0.0\n",
    "    for i in range(0,upper_boundary_condition+2):\n",
    "        df['queue_length_%d'%(i)] = 0.0\n",
    "    t = 1\n",
    "    for page in range(TP_m_num):\n",
    "        with open('TP_1_%d.pkl' %(page), 'rb') as infile:\n",
    "            TP_1 = pickle.load(infile)\n",
    "        with open('TP_m_%d.pkl' %(page), 'rb') as infile:\n",
    "            TP_m = pickle.load(infile)\n",
    "        for k in range(len(TP_m)):\n",
    "            for j in range(t,upper_boundary_condition): #  possible values for enqueues\n",
    "                px = ((TP_1[k][0,j-t])*(TP_m[k][j-t,0]))/(np.dot(TP_1[k],TP_m[k]))\n",
    "                df.at[t, 'cumulative_enqueue_%d'%(j+1)] = px\n",
    "                df.at[t, 'queue_length_%d'%(j-t)] = px\n",
    "            t = t+1\n",
    "    for page in range(TP_m_num):\n",
    "        os.remove('TP_1_%d.pkl' %(page))\n",
    "    for page in range(TP_m_num):\n",
    "        os.remove('TP_m_%d.pkl' %(page))\n",
    "    df.at[0, 'cumulative_enqueue_%d'%(1)] = 1\n",
    "    df.at[m, 'cumulative_enqueue_%d'%(upper_boundary_condition + 1)] = 1\n",
    "    df.at[m, 'queue_length_%d' %(upper_boundary_condition+1-m)] = 1\n",
    "    df.at[0, 'queue_length_0'] = 1\n",
    "    #reduce 0 columns\n",
    "    bound = upper_boundary_condition +1\n",
    "    for i in range(upper_boundary_condition+1, 0 , -1):\n",
    "        if np.all(df['queue_length_%d'%(i)] == 0.0):\n",
    "            df.drop(['queue_length_%d'%(i)], axis=1)\n",
    "            bound -= 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    # Caculate mean         \n",
    "    df['mean'] = 0.0\n",
    "    for j in range(bound+1):\n",
    "        df['mean'] += j*df['queue_length_%d'%(j)]\n",
    "    \n",
    "    # Caculate S.D.\n",
    "    k = df[\"mean\"].tolist()\n",
    "    k = np.asarray(k)\n",
    "    x = []\n",
    "    for i in range(len(df)):\n",
    "        y = 0.0\n",
    "        for j in range(bound+1):\n",
    "            y += math.pow((j-k[i]),2)*df.at[i,'queue_length_%d'%(j)]\n",
    "        x.append(y)\n",
    "    x = np.asarray(x)\n",
    "    x = np.sqrt(x)\n",
    "    df['sd'] = x\n",
    "    \n",
    "    # Caculate median \n",
    "    x = []\n",
    "    z = []\n",
    "    for i in range(len(df)):\n",
    "        y = 0.0\n",
    "        flag = 0\n",
    "        for j in range(bound+1):\n",
    "            y += df.at[i,'queue_length_%d'%(j)]\n",
    "            if y >= 0.5 and flag == 0:\n",
    "                x.append(j)\n",
    "                flag = 1\n",
    "            if y >= 0.9:\n",
    "                z.append(j)\n",
    "                break\n",
    "    df['median'] = x\n",
    "    df['90_quantile'] = z\n",
    "    \n",
    "    # Caculate mode\n",
    "    x = []\n",
    "    for i in range(len(df)):\n",
    "        y = 0.0\n",
    "        k = 0\n",
    "        for j in range(bound+1):\n",
    "            if df.at[i,'queue_length_%d'%(j)] > y:\n",
    "                y = df.at[i,'queue_length_%d'%(j)] \n",
    "                k = j\n",
    "        x.append(k)\n",
    "    df['mode'] = x\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function add all the service timestamps occures after last arrival\n",
    "def add_reminder_times(result, z_ex, m, upper_boundary_condition, flag ):\n",
    "    extend = pd.DataFrame(z_ex, columns =['time']) \n",
    "    print(len(extend))\n",
    "    x = []\n",
    "    for i in range(1,upper_boundary_condition+1):\n",
    "        extend['cumulative_enqueue_%d'%(i)] = 0.0\n",
    "    for i in range(0,upper_boundary_condition+2):\n",
    "        extend['queue_length_%d'%(i)] = 0.0\n",
    "    extend['cumulative_enqueue_%d'%(upper_boundary_condition + 1)] = 1.0\n",
    "    for k in range(len(extend)):\n",
    "        extend.at[k, 'queue_length_%d' %(upper_boundary_condition+1-m-k-1)] = 1\n",
    "        x.append(upper_boundary_condition+1-m-k-1)\n",
    "        \n",
    "    extend['mean'] = x\n",
    "    extend['sd'] = 0.0\n",
    "    extend['median'] = x\n",
    "    extend['90_quantile'] = x\n",
    "    extend['mode'] = x\n",
    "    \n",
    "    result_1 = result\n",
    "    if flag == 1:\n",
    "        result_1 = result_1[:-1]\n",
    "    result_1 = result_1.drop(['index'], axis=1)\n",
    "    \n",
    "    frames = [result_1, extend]\n",
    "    result_2 = pd.concat(frames,  ignore_index = True)\n",
    "    \n",
    "    return result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(full_df, max_enqueue, result, m):\n",
    "    right = full_df\n",
    "    right = right.sort_values(by=['order'])\n",
    "    right = right[['order','queue_length', 'wt', 'arrival']]\n",
    "    min_order = right['order'].min()\n",
    "    right['order'] = right['order'] - min_order\n",
    "    right = right.rename(columns={'order': 'index'})\n",
    "    result = pd.merge(result, right, on=['index', 'index'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementaion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV reqired at least sortes 'service' column \n",
    "df = pd.read_csv('simulations/busy_periods/bp_%d.csv' %(j)) \n",
    "enqueue_vec = df['enqueue'].to_numpy()\n",
    "enqueue_vec = np.sort(enqueue_vec)\n",
    "df['inter_arr'] = 0\n",
    "for i in range(1,len(df)):\n",
    "    df.at[i,'inter_arr'] = enqueue_vec[i]-enqueue_vec[i-1]\n",
    "arrival_rate = float(1/np.mean(df['inter_arr'])) #requiered\n",
    "                \n",
    "max_list = 500 # size of pickles files for calculations \n",
    "\n",
    "# Relevant information to the Algorithm \n",
    "max_enqueue = df['enqueue'].max() #requiered\n",
    "# Boundary conditions\n",
    "l = len(df) \n",
    "upper_boundary_condition = l - 1 # index start from 0, for the (l-1) customer need to subtract 1\n",
    "\n",
    "# Index continuity\n",
    "z, flag = build_index_continuity(df , max_enqueue )\n",
    "z_ex = build_ex_times(df , max_enqueue)\n",
    "        \n",
    "m = len(z) - 1  # index start from 0, for the (m) customer need to subtract 1\n",
    "\n",
    "# Admissible (non-taboo) states\n",
    "G = build_admissible_states(m , upper_boundary_condition )\n",
    "        \n",
    "# (1) Define transition matrices between admissible states\n",
    "P_num = build_transition_matrices(G, z, m, upper_boundary_condition, arrival_rate, max_list)\n",
    "        \n",
    "# (2) Calculating the matrices of taboo probabilities\n",
    "TP_m_num = Calculate_taboo_probabilities(P_num) \n",
    "        \n",
    "# (3) Calculating the distribution for cumulative number of arrivals\n",
    "result = Calculating_distribution(TP_m_num , z, m, upper_boundary_condition )\n",
    "result_1 = add_reminder_times(result, z_ex, m, upper_boundary_condition, flag ) \n",
    "result_1.reset_index(inplace=True)\n",
    "result_1 = add_labels(df, max_enqueue, result_1, m )\n",
    "        \n",
    "\n",
    "#Save result\n",
    "result_1.to_csv(r'QIE_outputs/res_%s.csv' %(j), index = False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
